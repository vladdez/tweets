{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 0. Getting ready"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk import WordNetLemmatizer\n",
    "from autocorrect import Speller\n",
    "import warnings\n",
    "import multiprocessing as mp\n",
    "warnings.filterwarnings('ignore')\n",
    "from numpy.linalg import norm\n",
    "import itertools\n",
    "from numpy import dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "'C:\\\\Users\\\\Vladimir\\\\DataspellProjects\\\\tweetsdata\\\\'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd() + 'data\\\\'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 tweets  sentiment\n12    Errr dude.... They're gone unhappy  Asked othe...         -1\n1651                              as petitioner wants.           0\n1456                                      Daddy dearest          0\n1110                                 unhappy  they not          -1\n2536            claims he has the masses. Who decides?           0\n...                                                 ...        ...\n3169                                            hi cham          1\n2359  5-judge constitution bench to sit in May to de...          0\n3160              Thank you so much my friend smile  xx          1\n2577                            Shades of in law change          0\n1653   MP put on no-fly list by for pervert airlines...          0\n\n[3868 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweets</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>12</th>\n      <td>Errr dude.... They're gone unhappy  Asked othe...</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>1651</th>\n      <td>as petitioner wants.</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1456</th>\n      <td>Daddy dearest</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1110</th>\n      <td>unhappy  they not</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>2536</th>\n      <td>claims he has the masses. Who decides?</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3169</th>\n      <td>hi cham</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2359</th>\n      <td>5-judge constitution bench to sit in May to de...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3160</th>\n      <td>Thank you so much my friend smile  xx</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2577</th>\n      <td>Shades of in law change</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1653</th>\n      <td>MP put on no-fly list by for pervert airlines...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3868 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = pd.read_csv('data/processedNegative.csv', header=None).T.assign(sentiment=-1)\n",
    "b = pd.read_csv('data/processedNeutral.csv', header=None).T.assign(sentiment=0)\n",
    "c = pd.read_csv('data/processedPositive.csv', header=None).T.assign(sentiment=1)\n",
    "\n",
    "my_tweets = []\n",
    "my_tweets = pd.concat([a, b, c], axis = 0, ignore_index=True)\n",
    "my_tweets = shuffle(my_tweets)\n",
    "my_tweets.columns = ['tweets', 'sentiment']\n",
    "my_tweets.dropna(subset=['tweets'], inplace = True)\n",
    "my_tweets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Data preparation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## tokenization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def tokenizer(col, is_stopwords):\n",
    "    tokens = nltk.word_tokenize(str(col).lower())\n",
    "    # delete all punctuation marks and numbers\n",
    "    tokens = [i for i in tokens if (i not in string.punctuation)]\n",
    "    tokens = [i for i in tokens if i.isalpha()]\n",
    "\n",
    "    # delete stop words\n",
    "    if (not is_stopwords):\n",
    "        stop_words = stopwords.words('english')\n",
    "        tokens = [i for i in tokens if (i not in stop_words)]\n",
    "\n",
    "    return tokens"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 tweets  sentiment  \\\n0     Errr dude.... They're gone unhappy  Asked othe...         -1   \n1                                 as petitioner wants.           0   \n2                                         Daddy dearest          0   \n3                                    unhappy  they not          -1   \n4               claims he has the masses. Who decides?           0   \n...                                                 ...        ...   \n3825                                            hi cham          1   \n3826  5-judge constitution bench to sit in May to de...          0   \n3827              Thank you so much my friend smile  xx          1   \n3828                            Shades of in law change          0   \n3829   MP put on no-fly list by for pervert airlines...          0   \n\n                                                 tokens  \\\n0     [errr, dude, gone, unhappy, asked, league, mem...   \n1                                   [petitioner, wants]   \n2                                      [daddy, dearest]   \n3                                             [unhappy]   \n4                             [claims, masses, decides]   \n...                                                 ...   \n3825                                         [hi, cham]   \n3826  [constitution, bench, sit, may, decide, pleas,...   \n3827                   [thank, much, friend, smile, xx]   \n3828                              [shades, law, change]   \n3829           [mp, put, list, pervert, airlines, well]   \n\n                                  tokens_with_stopwords  \n0     [errr, dude, they, gone, unhappy, asked, other...  \n1                               [as, petitioner, wants]  \n2                                      [daddy, dearest]  \n3                                  [unhappy, they, not]  \n4          [claims, he, has, the, masses, who, decides]  \n...                                                 ...  \n3825                                         [hi, cham]  \n3826  [constitution, bench, to, sit, in, may, to, de...  \n3827      [thank, you, so, much, my, friend, smile, xx]  \n3828                      [shades, of, in, law, change]  \n3829  [mp, put, on, list, by, for, pervert, airlines...  \n\n[3830 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweets</th>\n      <th>sentiment</th>\n      <th>tokens</th>\n      <th>tokens_with_stopwords</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Errr dude.... They're gone unhappy  Asked othe...</td>\n      <td>-1</td>\n      <td>[errr, dude, gone, unhappy, asked, league, mem...</td>\n      <td>[errr, dude, they, gone, unhappy, asked, other...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>as petitioner wants.</td>\n      <td>0</td>\n      <td>[petitioner, wants]</td>\n      <td>[as, petitioner, wants]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Daddy dearest</td>\n      <td>0</td>\n      <td>[daddy, dearest]</td>\n      <td>[daddy, dearest]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>unhappy  they not</td>\n      <td>-1</td>\n      <td>[unhappy]</td>\n      <td>[unhappy, they, not]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>claims he has the masses. Who decides?</td>\n      <td>0</td>\n      <td>[claims, masses, decides]</td>\n      <td>[claims, he, has, the, masses, who, decides]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3825</th>\n      <td>hi cham</td>\n      <td>1</td>\n      <td>[hi, cham]</td>\n      <td>[hi, cham]</td>\n    </tr>\n    <tr>\n      <th>3826</th>\n      <td>5-judge constitution bench to sit in May to de...</td>\n      <td>0</td>\n      <td>[constitution, bench, sit, may, decide, pleas,...</td>\n      <td>[constitution, bench, to, sit, in, may, to, de...</td>\n    </tr>\n    <tr>\n      <th>3827</th>\n      <td>Thank you so much my friend smile  xx</td>\n      <td>1</td>\n      <td>[thank, much, friend, smile, xx]</td>\n      <td>[thank, you, so, much, my, friend, smile, xx]</td>\n    </tr>\n    <tr>\n      <th>3828</th>\n      <td>Shades of in law change</td>\n      <td>0</td>\n      <td>[shades, law, change]</td>\n      <td>[shades, of, in, law, change]</td>\n    </tr>\n    <tr>\n      <th>3829</th>\n      <td>MP put on no-fly list by for pervert airlines...</td>\n      <td>0</td>\n      <td>[mp, put, list, pervert, airlines, well]</td>\n      <td>[mp, put, on, list, by, for, pervert, airlines...</td>\n    </tr>\n  </tbody>\n</table>\n<p>3830 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = my_tweets\n",
    "tweets['tokens'] = tweets['tweets'].apply(lambda  x : tokenizer(x, False))\n",
    "tweets['tokens_with_stopwords'] = tweets['tweets'].apply(lambda  x : tokenizer(x, True))\n",
    "\n",
    "tweets = tweets[tweets['tokens'].map(lambda x : len(x)) > 0]\n",
    "tweets = tweets[tweets['tokens_with_stopwords'].map(lambda x : len(x)) > 0]\n",
    "tweets.reset_index(drop=True, inplace = True)\n",
    "tweets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## stemming"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 tweets  sentiment  \\\n0     Errr dude.... They're gone unhappy  Asked othe...         -1   \n1                                 as petitioner wants.           0   \n2                                         Daddy dearest          0   \n3                                    unhappy  they not          -1   \n4               claims he has the masses. Who decides?           0   \n...                                                 ...        ...   \n3825                                            hi cham          1   \n3826  5-judge constitution bench to sit in May to de...          0   \n3827              Thank you so much my friend smile  xx          1   \n3828                            Shades of in law change          0   \n3829   MP put on no-fly list by for pervert airlines...          0   \n\n                                                 tokens  \\\n0     [errr, dude, gone, unhappy, asked, league, mem...   \n1                                   [petitioner, wants]   \n2                                      [daddy, dearest]   \n3                                             [unhappy]   \n4                             [claims, masses, decides]   \n...                                                 ...   \n3825                                         [hi, cham]   \n3826  [constitution, bench, sit, may, decide, pleas,...   \n3827                   [thank, much, friend, smile, xx]   \n3828                              [shades, law, change]   \n3829           [mp, put, list, pervert, airlines, well]   \n\n                                  tokens_with_stopwords  \\\n0     [errr, dude, they, gone, unhappy, asked, other...   \n1                               [as, petitioner, wants]   \n2                                      [daddy, dearest]   \n3                                  [unhappy, they, not]   \n4          [claims, he, has, the, masses, who, decides]   \n...                                                 ...   \n3825                                         [hi, cham]   \n3826  [constitution, bench, to, sit, in, may, to, de...   \n3827      [thank, you, so, much, my, friend, smile, xx]   \n3828                      [shades, of, in, law, change]   \n3829  [mp, put, on, list, by, for, pervert, airlines...   \n\n                                                stemmed  \n0     [errr, dude, gone, unhappi, ask, leagu, memeb,...  \n1                                      [petition, want]  \n2                                      [daddi, dearest]  \n3                                             [unhappi]  \n4                                  [claim, mass, decid]  \n...                                                 ...  \n3825                                         [hi, cham]  \n3826  [constitut, bench, sit, may, decid, plea, rela...  \n3827                   [thank, much, friend, smile, xx]  \n3828                                [shade, law, chang]  \n3829             [mp, put, list, pervert, airlin, well]  \n\n[3830 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweets</th>\n      <th>sentiment</th>\n      <th>tokens</th>\n      <th>tokens_with_stopwords</th>\n      <th>stemmed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Errr dude.... They're gone unhappy  Asked othe...</td>\n      <td>-1</td>\n      <td>[errr, dude, gone, unhappy, asked, league, mem...</td>\n      <td>[errr, dude, they, gone, unhappy, asked, other...</td>\n      <td>[errr, dude, gone, unhappi, ask, leagu, memeb,...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>as petitioner wants.</td>\n      <td>0</td>\n      <td>[petitioner, wants]</td>\n      <td>[as, petitioner, wants]</td>\n      <td>[petition, want]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Daddy dearest</td>\n      <td>0</td>\n      <td>[daddy, dearest]</td>\n      <td>[daddy, dearest]</td>\n      <td>[daddi, dearest]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>unhappy  they not</td>\n      <td>-1</td>\n      <td>[unhappy]</td>\n      <td>[unhappy, they, not]</td>\n      <td>[unhappi]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>claims he has the masses. Who decides?</td>\n      <td>0</td>\n      <td>[claims, masses, decides]</td>\n      <td>[claims, he, has, the, masses, who, decides]</td>\n      <td>[claim, mass, decid]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3825</th>\n      <td>hi cham</td>\n      <td>1</td>\n      <td>[hi, cham]</td>\n      <td>[hi, cham]</td>\n      <td>[hi, cham]</td>\n    </tr>\n    <tr>\n      <th>3826</th>\n      <td>5-judge constitution bench to sit in May to de...</td>\n      <td>0</td>\n      <td>[constitution, bench, sit, may, decide, pleas,...</td>\n      <td>[constitution, bench, to, sit, in, may, to, de...</td>\n      <td>[constitut, bench, sit, may, decid, plea, rela...</td>\n    </tr>\n    <tr>\n      <th>3827</th>\n      <td>Thank you so much my friend smile  xx</td>\n      <td>1</td>\n      <td>[thank, much, friend, smile, xx]</td>\n      <td>[thank, you, so, much, my, friend, smile, xx]</td>\n      <td>[thank, much, friend, smile, xx]</td>\n    </tr>\n    <tr>\n      <th>3828</th>\n      <td>Shades of in law change</td>\n      <td>0</td>\n      <td>[shades, law, change]</td>\n      <td>[shades, of, in, law, change]</td>\n      <td>[shade, law, chang]</td>\n    </tr>\n    <tr>\n      <th>3829</th>\n      <td>MP put on no-fly list by for pervert airlines...</td>\n      <td>0</td>\n      <td>[mp, put, list, pervert, airlines, well]</td>\n      <td>[mp, put, on, list, by, for, pervert, airlines...</td>\n      <td>[mp, put, list, pervert, airlin, well]</td>\n    </tr>\n  </tbody>\n</table>\n<p>3830 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = SnowballStemmer(language='english')\n",
    "tweets['stemmed'] = tweets['tokens'].apply(lambda x : [stemmer.stem(word) for word in x])\n",
    "tweets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## lemmatization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Vladimir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                 tweets  sentiment  \\\n0     i took a full drink into my uber; i guess you ...          1   \n1                                    I need cheering up         -1   \n2     imagine if he wins next time too unhappy  unha...         -1   \n3                             follow mee plss unhappy           -1   \n4               Education rankings throw up surprises.           0   \n...                                                 ...        ...   \n3825  IF YOU ARE READING THIS I HOPE SOMETHING GREAT...          1   \n3826                         What a sad life it must be          1   \n3827                                  Offline  unhappy          -1   \n3828  People who don%27t know me always think I am q...          1   \n3829   but court orders further probe into corruptio...          0   \n\n                                                 tokens  \\\n0     [took, full, drink, uber, guess, could, say, i...   \n1                                      [need, cheering]   \n2         [imagine, wins, next, time, unhappy, unhappy]   \n3                          [follow, mee, plss, unhappy]   \n4               [education, rankings, throw, surprises]   \n...                                                 ...   \n3825  [reading, hope, something, great, happens, smile]   \n3826                                  [sad, life, must]   \n3827                                 [offline, unhappy]   \n3828  [people, know, always, think, quiet, people, k...   \n3829         [court, orders, probe, corruption, charge]   \n\n                                  tokens_with_stopwords  \\\n0     [i, took, a, full, drink, into, my, uber, i, g...   \n1                               [i, need, cheering, up]   \n2     [imagine, if, he, wins, next, time, too, unhap...   \n3                          [follow, mee, plss, unhappy]   \n4           [education, rankings, throw, up, surprises]   \n...                                                 ...   \n3825  [if, you, are, reading, this, i, hope, somethi...   \n3826                 [what, a, sad, life, it, must, be]   \n3827                                 [offline, unhappy]   \n3828  [people, who, don, know, me, always, think, i,...   \n3829  [but, court, orders, further, probe, into, cor...   \n\n                                                stemmed  \\\n0     [took, full, drink, uber, guess, could, say, i...   \n1                                         [need, cheer]   \n2           [imagin, win, next, time, unhappi, unhappi]   \n3                          [follow, mee, plss, unhappi]   \n4                          [educ, rank, throw, surpris]   \n...                                                 ...   \n3825         [read, hope, someth, great, happen, smile]   \n3826                                  [sad, life, must]   \n3827                                  [offlin, unhappi]   \n3828  [peopl, know, alway, think, quiet, peopl, know...   \n3829              [court, order, probe, corrupt, charg]   \n\n                                             lemmatized  \n0     [took, full, drink, uber, guess, could, say, i...  \n1                                      [need, cheering]  \n2          [imagine, win, next, time, unhappy, unhappy]  \n3                          [follow, mee, plss, unhappy]  \n4                 [education, ranking, throw, surprise]  \n...                                                 ...  \n3825  [reading, hope, something, great, happens, smile]  \n3826                                  [sad, life, must]  \n3827                                 [offline, unhappy]  \n3828  [people, know, always, think, quiet, people, k...  \n3829          [court, order, probe, corruption, charge]  \n\n[3830 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweets</th>\n      <th>sentiment</th>\n      <th>tokens</th>\n      <th>tokens_with_stopwords</th>\n      <th>stemmed</th>\n      <th>lemmatized</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>i took a full drink into my uber; i guess you ...</td>\n      <td>1</td>\n      <td>[took, full, drink, uber, guess, could, say, i...</td>\n      <td>[i, took, a, full, drink, into, my, uber, i, g...</td>\n      <td>[took, full, drink, uber, guess, could, say, i...</td>\n      <td>[took, full, drink, uber, guess, could, say, i...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I need cheering up</td>\n      <td>-1</td>\n      <td>[need, cheering]</td>\n      <td>[i, need, cheering, up]</td>\n      <td>[need, cheer]</td>\n      <td>[need, cheering]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>imagine if he wins next time too unhappy  unha...</td>\n      <td>-1</td>\n      <td>[imagine, wins, next, time, unhappy, unhappy]</td>\n      <td>[imagine, if, he, wins, next, time, too, unhap...</td>\n      <td>[imagin, win, next, time, unhappi, unhappi]</td>\n      <td>[imagine, win, next, time, unhappy, unhappy]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>follow mee plss unhappy</td>\n      <td>-1</td>\n      <td>[follow, mee, plss, unhappy]</td>\n      <td>[follow, mee, plss, unhappy]</td>\n      <td>[follow, mee, plss, unhappi]</td>\n      <td>[follow, mee, plss, unhappy]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Education rankings throw up surprises.</td>\n      <td>0</td>\n      <td>[education, rankings, throw, surprises]</td>\n      <td>[education, rankings, throw, up, surprises]</td>\n      <td>[educ, rank, throw, surpris]</td>\n      <td>[education, ranking, throw, surprise]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3825</th>\n      <td>IF YOU ARE READING THIS I HOPE SOMETHING GREAT...</td>\n      <td>1</td>\n      <td>[reading, hope, something, great, happens, smile]</td>\n      <td>[if, you, are, reading, this, i, hope, somethi...</td>\n      <td>[read, hope, someth, great, happen, smile]</td>\n      <td>[reading, hope, something, great, happens, smile]</td>\n    </tr>\n    <tr>\n      <th>3826</th>\n      <td>What a sad life it must be</td>\n      <td>1</td>\n      <td>[sad, life, must]</td>\n      <td>[what, a, sad, life, it, must, be]</td>\n      <td>[sad, life, must]</td>\n      <td>[sad, life, must]</td>\n    </tr>\n    <tr>\n      <th>3827</th>\n      <td>Offline  unhappy</td>\n      <td>-1</td>\n      <td>[offline, unhappy]</td>\n      <td>[offline, unhappy]</td>\n      <td>[offlin, unhappi]</td>\n      <td>[offline, unhappy]</td>\n    </tr>\n    <tr>\n      <th>3828</th>\n      <td>People who don%27t know me always think I am q...</td>\n      <td>1</td>\n      <td>[people, know, always, think, quiet, people, k...</td>\n      <td>[people, who, don, know, me, always, think, i,...</td>\n      <td>[peopl, know, alway, think, quiet, peopl, know...</td>\n      <td>[people, know, always, think, quiet, people, k...</td>\n    </tr>\n    <tr>\n      <th>3829</th>\n      <td>but court orders further probe into corruptio...</td>\n      <td>0</td>\n      <td>[court, orders, probe, corruption, charge]</td>\n      <td>[but, court, orders, further, probe, into, cor...</td>\n      <td>[court, order, probe, corrupt, charg]</td>\n      <td>[court, order, probe, corruption, charge]</td>\n    </tr>\n  </tbody>\n</table>\n<p>3830 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tweets['lemmatized'] = tweets['tokens'].apply(lambda x : [lemmatizer.lemmatize(word) for word in x])\n",
    "tweets\n",
    "# could be also used misspelling"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## misspelling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "spell = Speller(lang = 'en')\n",
    "tweets['misspelling'] = tweets['tokens'].apply(lambda x : [stemmer.stem(spell(word)) for word in x])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "tweets['lemma + misspell'] = tweets['tokens'].apply(lambda x : [lemmatizer.lemmatize(spell(word)) for word in x])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Vectorization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Word exists"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "we = CountVectorizer(binary=True)\n",
    "x_we = we.fit_transform(tweets[\"tokens\"].astype('str'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "<3830x5910 sparse matrix of type '<class 'numpy.int64'>'\n\twith 19261 stored elements in Compressed Sparse Row format>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_we"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Bag of words"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "x_bow = cv.fit_transform(tweets[\"tokens\"].astype('str'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TF-IDF"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "tv = TfidfVectorizer()\n",
    "x_tfidf = tv.fit_transform(tweets[\"tokens\"].astype('str'))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Word2Vec"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "outputs": [
    {
     "data": {
      "text/plain": "8"
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp.cpu_count()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "modelW2V = Word2Vec(\n",
    "                    window=3,\n",
    "                    sample=6e-5,\n",
    "                    alpha=0.03,\n",
    "                    min_alpha=0.0007,\n",
    "                    negative=10,\n",
    "                    vector_size=300, # number of neurons in hidden layer of NN\n",
    "                    min_count=5, # word will count if it occurs N times in all tweets\n",
    "                    workers=8) # depends on number of CPU cores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "modelW2V.build_vocab(tweets['tokens'], progress_per=10000)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "(132634, 982300)"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelW2V.train(tweets['tokens'], total_examples=modelW2V.corpus_count, epochs=50, report_delay=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "array([-1.51315108e-01,  5.50881565e-01, -9.51377116e-03,  2.80250639e-01,\n        3.60852838e-01,  4.00167471e-03,  3.06205750e-01,  6.20851517e-01,\n        1.39004648e-01, -6.04955666e-03, -1.59224570e-01, -3.20364207e-01,\n       -5.83596621e-03, -4.15915936e-01, -1.88780218e-01, -6.73910558e-01,\n       -4.97146063e-02,  9.10909548e-02, -2.03169510e-01,  2.72166245e-02,\n       -5.54300487e-01, -2.62648582e-01,  1.72311872e-01,  1.23393558e-01,\n        2.35696346e-01, -1.03093155e-01, -3.67407799e-01,  1.17574632e-01,\n       -1.00561447e-01, -5.41165173e-01, -6.18582591e-02, -9.27833617e-02,\n        8.54666755e-02, -3.47621173e-01, -1.93278193e-01,  1.56919867e-01,\n        2.09297523e-01, -3.45100760e-01,  1.04102165e-01,  2.42870435e-01,\n       -5.73552512e-02,  5.03180623e-02,  1.32043034e-01, -5.34826294e-02,\n       -2.02198192e-01,  1.78821161e-01,  2.45689422e-01, -3.21193129e-01,\n       -1.63090557e-01,  1.01494126e-01,  2.91389897e-02, -2.05518380e-01,\n       -3.38081837e-01,  2.01657955e-02, -6.30199984e-02,  1.23249963e-01,\n        4.26247209e-01, -3.56515706e-01, -2.18502194e-01,  1.53679073e-01,\n       -4.84171063e-01, -3.01101297e-01,  3.01218927e-01, -1.95847005e-01,\n       -1.92168355e-01,  6.43682405e-02,  1.39338121e-01,  2.77229939e-02,\n        9.41599079e-04,  1.20385997e-01, -1.97154999e-01,  2.37692874e-02,\n        3.81110519e-01, -2.03287929e-01,  1.31240264e-01, -8.55589956e-02,\n       -3.97444218e-01, -2.15876848e-02, -1.56377882e-01,  3.78942966e-01,\n       -1.24932557e-01, -2.77692497e-01,  1.34863809e-01,  5.44616356e-02,\n        6.06677905e-02, -6.33818805e-02, -6.27579629e-01, -1.63630113e-01,\n       -6.46231472e-02, -2.97701955e-02,  3.01231891e-01, -3.83354500e-02,\n        2.04569310e-01,  2.49060690e-01,  2.36211464e-01,  1.68805003e-01,\n        6.88056529e-01, -1.74187422e-01, -1.74266219e-01,  2.37047955e-01,\n        1.20202944e-01, -1.83720328e-02,  1.00750469e-01,  1.13164186e-01,\n        2.27737367e-01, -3.37102860e-01, -1.79501280e-01, -1.42251819e-01,\n       -9.95192155e-02, -2.03088835e-01, -1.35568246e-01,  3.81734520e-02,\n       -1.59032065e-02,  2.05670774e-01,  6.56536818e-02,  5.11416830e-02,\n        2.12228924e-01,  1.34336591e-01,  3.25222850e-01, -9.84558016e-02,\n       -3.74202996e-01,  7.35376850e-02,  6.88680857e-02, -1.56164616e-01,\n       -2.12346315e-01, -5.27954027e-02, -2.46669576e-01, -1.04173064e-01,\n       -2.20051900e-01,  5.26399970e-01, -7.20827281e-02,  1.15959980e-01,\n        1.55791698e-04, -5.88833988e-01, -2.19963677e-02, -1.72599375e-01,\n        5.67910671e-02,  6.89808163e-04, -1.16804309e-01, -7.17263371e-02,\n       -1.43288091e-01, -1.00087479e-01, -6.43845499e-02,  1.56457752e-01,\n        7.39555582e-02, -3.20396781e-01, -2.61563063e-01, -3.70010316e-01,\n       -2.98760116e-01, -1.46560684e-01, -2.98565179e-01,  6.28633648e-02,\n        9.44839492e-02,  7.06674680e-02, -4.10894275e-01,  2.30458006e-01,\n       -2.29049120e-02,  3.22674215e-02,  8.45038891e-02, -1.71821758e-01,\n       -1.55266926e-01, -4.03771512e-02, -3.74381304e-01,  1.41625538e-01,\n       -1.73522174e-01,  2.32273549e-01,  1.97109669e-01,  1.67952403e-01,\n        2.03704372e-01,  3.25104535e-01,  7.15998635e-02,  1.41055480e-01,\n       -9.16287303e-02,  2.95406520e-01,  3.28829527e-01,  8.75529721e-02,\n       -1.46868210e-02,  1.45378737e-02, -2.22945482e-01, -4.68187094e-01,\n        7.33854994e-02,  1.31460741e-01,  7.88217112e-02,  3.72212455e-02,\n       -1.28683552e-01,  5.70617616e-02,  9.96195972e-02,  3.45374316e-01,\n        2.31546298e-01, -2.24333227e-01,  9.13590118e-02, -1.33807614e-01,\n        1.05018662e-02, -8.46198052e-02, -6.16131388e-02, -2.58501768e-01,\n        2.87959069e-01, -1.15041479e-01,  1.07538104e-01, -3.39478046e-01,\n       -2.52160609e-01,  4.77560610e-02, -1.06202170e-01, -4.65647101e-01,\n       -4.98251757e-03, -2.45050043e-01,  7.78656974e-02, -3.71441431e-02,\n        7.31212571e-02, -5.61446249e-01,  2.42877156e-01, -3.13796669e-01,\n       -3.53219062e-01,  1.30208852e-02,  1.90860882e-01, -2.47434661e-01,\n       -1.23073295e-01, -3.13277662e-01, -2.50611722e-01,  4.77968790e-02,\n        2.84160376e-01, -2.75821000e-01,  7.41236880e-02,  9.23845917e-02,\n       -9.59301740e-02, -6.77662969e-01, -7.71060511e-02,  4.03519660e-01,\n       -3.06105077e-01,  3.51848960e-01, -6.17680252e-02,  1.33964613e-01,\n       -3.56908917e-01,  8.41500983e-02,  1.77219331e-01,  1.57096490e-01,\n        1.33163154e-01,  1.30930305e-01, -1.69708394e-02, -6.60183191e-01,\n       -3.26220393e-02, -1.33104354e-01, -2.83038557e-01,  4.45775539e-02,\n        9.56038088e-02, -5.13167262e-01,  1.95551410e-01, -3.12919557e-01,\n        1.70430854e-01,  3.90366435e-01, -3.33400853e-02,  4.29157875e-02,\n       -7.79561326e-02,  1.12517387e-01, -3.32313627e-01, -3.46954405e-01,\n        5.86305857e-01,  1.57554597e-01, -3.81182492e-01, -3.61046225e-01,\n       -1.83330998e-02,  4.13445421e-02,  2.87094563e-02,  1.60619214e-01,\n        2.92818788e-02, -2.89630473e-01,  1.74488500e-01,  5.06792545e-01,\n       -2.22506925e-01,  2.24027306e-01, -1.99929625e-02, -4.84637432e-02,\n        2.42874138e-02, -1.24517037e-02,  5.14895260e-01, -1.49560064e-01,\n        1.92364112e-01, -5.42683061e-03,  4.16813940e-01,  5.85574657e-02,\n        2.75472969e-01, -3.53984535e-01,  2.84099635e-02,  5.05919755e-02,\n       -3.03707533e-02, -2.51488894e-01, -2.51126856e-01,  4.22930151e-01,\n        2.11390764e-01,  3.73499334e-01, -2.08327770e-01,  9.95147005e-02,\n        3.43411937e-02,  7.26296306e-02,  1.53423771e-01,  8.57678413e-01,\n        1.41047776e-01, -3.64039876e-02, -2.59601146e-01,  2.48000361e-02],\n      dtype=float32)"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelW2V.wv[1] # vector of values of hidden layer neurons for the word"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "[('charge', 0.9996358156204224),\n ('place', 0.9996321201324463),\n ('work', 0.9996307492256165),\n ('social', 0.9996282458305359),\n ('put', 0.999627411365509),\n ('wants', 0.9996249079704285),\n ('today', 0.9996242523193359),\n ('governor', 0.9996238946914673),\n ('really', 0.9996238350868225),\n ('cm', 0.9996156692504883)]"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelW2V.wv.most_similar(positive=[\"man\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Classification for sentiment analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# function to compute tweet vectors from word vectors\n",
    "def text2vec(text, model_w2v):\n",
    "    sent_vectors = []\n",
    "    for word in text:\n",
    "        try:\n",
    "            sent_vectors.append(model_w2v.wv[word]) # appending all word vectors\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return np.sum(sent_vectors, axis=0) / len(sent_vectors) # normalization"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [],
   "source": [
    "# vectorisation methods\n",
    "meth_dict = {\"WE\" : CountVectorizer(binary=True),\n",
    "             \"BoW\" : CountVectorizer(),\n",
    "             \"TF-IDF\" : TfidfVectorizer(),\n",
    "             \"Word2Vec\" : modelW2V\n",
    "             }\n",
    "\n",
    "# classifiers\n",
    "class_list = [\n",
    "    RandomForestClassifier(n_estimators=1000, random_state=1),\n",
    "    SVC(C = 0.5, kernel='linear', gamma='auto'), # these parameters were established using by GridSearch\n",
    "    LogisticRegression(solver='liblinear')\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizer: WE, Classifier: LogisticRegression, Preprocessing method: tokens, \n",
      "Accuracy: 0.862\n",
      "Vectorizer: BoW, Classifier: LogisticRegression, Preprocessing method: tokens, \n",
      "Accuracy: 0.858\n",
      "Vectorizer: TF-IDF, Classifier: LogisticRegression, Preprocessing method: tokens, \n",
      "Accuracy: 0.851\n",
      "Vectorizer: Word2Vec, Classifier: LogisticRegression, Preprocessing method: tokens, \n",
      "Accuracy: 0.834\n",
      "Vectorizer: WE, Classifier: LogisticRegression, Preprocessing method: tokens_with_stopwords, \n",
      "Accuracy: 0.875\n",
      "Vectorizer: BoW, Classifier: LogisticRegression, Preprocessing method: tokens_with_stopwords, \n",
      "Accuracy: 0.881\n",
      "Vectorizer: TF-IDF, Classifier: LogisticRegression, Preprocessing method: tokens_with_stopwords, \n",
      "Accuracy: 0.849\n",
      "Vectorizer: Word2Vec, Classifier: LogisticRegression, Preprocessing method: tokens_with_stopwords, \n",
      "Accuracy: 0.851\n",
      "Vectorizer: WE, Classifier: LogisticRegression, Preprocessing method: stemmed, \n",
      "Accuracy: 0.871\n",
      "Vectorizer: BoW, Classifier: LogisticRegression, Preprocessing method: stemmed, \n",
      "Accuracy: 0.883\n",
      "Vectorizer: TF-IDF, Classifier: LogisticRegression, Preprocessing method: stemmed, \n",
      "Accuracy: 0.866\n",
      "Vectorizer: Word2Vec, Classifier: LogisticRegression, Preprocessing method: stemmed, \n",
      "Accuracy: 0.837\n",
      "Vectorizer: WE, Classifier: LogisticRegression, Preprocessing method: lemmatized, \n",
      "Accuracy: 0.888\n",
      "Vectorizer: BoW, Classifier: LogisticRegression, Preprocessing method: lemmatized, \n",
      "Accuracy: 0.856\n",
      "Vectorizer: TF-IDF, Classifier: LogisticRegression, Preprocessing method: lemmatized, \n",
      "Accuracy: 0.867\n",
      "Vectorizer: Word2Vec, Classifier: LogisticRegression, Preprocessing method: lemmatized, \n",
      "Accuracy: 0.867\n",
      "Vectorizer: WE, Classifier: LogisticRegression, Preprocessing method: misspelling, \n",
      "Accuracy: 0.875\n",
      "Vectorizer: BoW, Classifier: LogisticRegression, Preprocessing method: misspelling, \n",
      "Accuracy: 0.883\n",
      "Vectorizer: TF-IDF, Classifier: LogisticRegression, Preprocessing method: misspelling, \n",
      "Accuracy: 0.866\n",
      "Vectorizer: Word2Vec, Classifier: LogisticRegression, Preprocessing method: misspelling, \n",
      "Accuracy: 0.812\n",
      "Vectorizer: WE, Classifier: LogisticRegression, Preprocessing method: lemma + misspell, \n",
      "Accuracy: 0.883\n",
      "Vectorizer: BoW, Classifier: LogisticRegression, Preprocessing method: lemma + misspell, \n",
      "Accuracy: 0.86\n",
      "Vectorizer: TF-IDF, Classifier: LogisticRegression, Preprocessing method: lemma + misspell, \n",
      "Accuracy: 0.863\n",
      "Vectorizer: Word2Vec, Classifier: LogisticRegression, Preprocessing method: lemma + misspell, \n",
      "Accuracy: 0.854\n"
     ]
    }
   ],
   "source": [
    "scores = {}\n",
    "for method in tweets.columns[2:]:\n",
    "    for name, vectorizer in meth_dict.items():\n",
    "        for classifier in class_list:\n",
    "            if name == \"Word2Vec\":\n",
    "                vectorizer.build_vocab(tweets[method], update=True)  # prepare the model vocabulary\n",
    "                vectorizer.train(tweets[method], total_examples=vectorizer.corpus_count, epochs= 400) #vectorizer.epochs)\n",
    "                # train word vectors\n",
    "                X = np.stack(tweets[method].apply(lambda row: text2vec(row, vectorizer)))\n",
    "            else:\n",
    "                X = vectorizer.fit_transform(tweets[method].astype(\"str\"))\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, tweets['sentiment'], test_size = 0.2, stratify=tweets['sentiment'])\n",
    "            classifier.fit(X_train, y_train)\n",
    "        scores[round(classifier.score(X_test, y_test), 3)] = name, method, classifier.__class__.__name__\n",
    "        print(\"Vectorizer: {}, Classifier: {}, Preprocessing method: {}, \\nAccuracy: {}\".format(\n",
    "            name, classifier.__class__.__name__, method, round(classifier.score(X_test, y_test), 3)))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best result:\n",
      "Vectorizer: WE, Classifier: lemmatized, Preprocessing method: LogisticRegression, \n",
      "Accuracy: 0.888\n"
     ]
    }
   ],
   "source": [
    "m = max(scores.keys())\n",
    "print(\"The best result:\\nVectorizer: {}, Classifier: {}, Preprocessing method: {}, \\nAccuracy: {}\".format(\n",
    "    scores[m][0], scores[m][2], scores[m][1], m))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GridSearch model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "GridSearchCV – это очень мощный инструмент для автоматического подбирания параметров для моделей машинного обучения. GridSearchCV находит наилучшие параметры, путем обычного перебора: он создает модель для каждой возможной комбинации параметров. Важно отметить, что такой подход может быть весьма времязатратным\n",
    "\n",
    "https://vc.ru/ml/147132-kak-avtomaticheski-podobrat-parametry-dlya-modeli-mashinnogo-obucheniya-ispolzuem-gridsearchcv\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# C-Support Vector Classification\n",
    "\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(tweets['stemmed'].astype('str'))\n",
    "\n",
    "param_grid = {'C' : [0.5, 0.7, 0.9, 1],\n",
    "              'gamma' : [10, 5, 4, 3, 2, 1.5],\n",
    "            'kernel' : ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "}\n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 1, n_jobs=10, cv=10)\n",
    "grid.fit(X, tweets['sentiment'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "{'C': 0.5, 'gamma': 10, 'kernel': 'linear'}"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8741514360313316"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_score_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Cosine similarity\n",
    "Cosine similarity is a metric, helpful in determining, how similar the data objects are irrespective of their size. We can measure the similarity between two sentences in Python using Cosine Similarity. In cosine similarity, data objects in a dataset are treated as a vector. The formula to find the cosine similarity between two vectors is –\n",
    "\n",
    "Cos(x, y) = x . y / ||x|| * ||y||\n",
    "\n",
    "https://www.geeksforgeeks.org/cosine-similarity/"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens\n",
      "\n",
      "tokens_with_stopwords\n",
      "\n",
      "stemmed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# available preprocessing methods\n",
    "for method in tweets.columns[2:]:\n",
    "    print(method + '\\n')\n",
    "    tweets[method].values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# function to find cosine distance\n",
    "def get_cosine(a, b):\n",
    "    return dot(a, b)/(norm(a)*norm(b))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def find_dist(sent): #sentence\n",
    "\n",
    "    # to avoid duplicates\n",
    "    sent = sent.apply(lambda x: ' '.join(x))\n",
    "    sent.drop_duplicates(inplace=True)\n",
    "    sent.reset_index(inplace=True, drop=True)\n",
    "    sent = sent.apply(lambda x: x.split(' '))\n",
    "\n",
    "    # to train model\n",
    "    m = Word2Vec(sent,  vector_size=300,\n",
    "                        min_count=1 ,\n",
    "                        workers=8)\n",
    "    m.build_vocab(tweets['tokens'], progress_per=10000)\n",
    "    m.train(tweets['tokens'], total_examples=m.corpus_count, epochs=50, report_delay=1)\n",
    "\n",
    "    # to create tweet vector from word vectors\n",
    "    sent_vectors = []\n",
    "    for word in sent:\n",
    "        sent_vectors.append(np.mean([m.wv[j] for j in word], axis=0))\n",
    "\n",
    "    # to count vector distances\n",
    "    distances = {}\n",
    "    r = 0\n",
    "    for i in range(0, len(sent_vectors)):\n",
    "       for j in range(i, len(sent_vectors)):\n",
    "    #for i in range(0, 10):\n",
    "        #for j in range(i, 10):\n",
    "            if i != j:\n",
    "                r += 1\n",
    "                distances[r] = (get_cosine(sent_vectors[i], sent_vectors[j]), i, j)\n",
    "\n",
    "    # to sort distances\n",
    "    s = dict(sorted(distances.items(), key=lambda x: x[1][0], reverse=True))\n",
    "    # to return top 10 similar tweets\n",
    "    return dict(itertools.islice(s.items(), 10))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "data": {
      "text/plain": "{815536: (1.0000001, 254, 1847),\n 89632: (0.9934575, 27, 73),\n 1258702: (0.9933491, 402, 643),\n 3174197: (0.9932755, 1151, 3192),\n 89593: (0.9917485, 27, 34),\n 1710500: (0.9910057, 560, 2220),\n 113302: (0.99075913, 34, 643),\n 198355: (0.98992485, 60, 325),\n 1066621: (0.9895986, 337, 1027),\n 2895065: (0.98914653, 1027, 2006)}"
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 10 similar distances for tokens\n",
    "\n",
    "res = find_dist(tweets['tokens'])\n",
    "res"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000001 |this is jimin to yoongi unhappy   \t|i want to hang out with them unhappy \n",
      "0.9934575 |BJP urges Governor Vidyasagar Rao to take a decision on basis of numbers as well as credibility.  \t|to WIN draw for free download of for Celebrate with us. Developed by for\n",
      "0.9933491 |52 injured as Jabalpur-Delhi train derails near half train carries on after delay.  \t|Lunchtime with Flinthook! This game has so much personality :D\n",
      "0.9932755 | but I liked seeing her posts and love her wri  \t| they're like 90 calories per piece unhappy  \n",
      "0.9917485 |BJP urges Governor Vidyasagar Rao to take a decision on basis of numbers as well as credibility.  \t|not clear right now. Speaker to decide....\n",
      "0.9910057 | House adjourned till 3pm. \t|How theatre festival got muffled. \n",
      "0.99075913 |not clear right now. Speaker to decide.... \t|Lunchtime with Flinthook! This game has so much personality :D\n",
      "0.98992485 |Thank you crew happy \t|How self-belief has kept him on top of the game. \n",
      "0.9895986 |Defence Partnership  \t|Happy 420 everyone happy\n",
      "0.98914653 |Happy 420 everyone happy \t|Attack on Westminster\n"
     ]
    }
   ],
   "source": [
    "for i, j, k in res.values():\n",
    "    print(i, '|' + tweets['tweets'][j], '\\t|' + tweets['tweets'][k])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.99999994 |.I can't believe this hasn't been fixed yet \t|Supreme Court quashes criminal complaint against cricketer for allegedly depicting himself as on magazine cover.\n",
      "0.9971929 |Thanks for the recent follow Happy to connect happy  have a great Thursday. Want it \t| contact. \n",
      "0.99715406 |Reservoirs to financial deal \t|Thanks for being top engaged community members this week happy   Want this\n",
      "0.9971358 |Death by currency \t|Such a lucky slave i wish this was me unhappy \n",
      "0.9967134 |000 in villages are taught to Google designs \t|One year ago today unhappy  \n",
      "0.99668497 |Hi! We tried to call your number but got no response unhappy  Please share another suitable time and an alternate number.. cont1 \t|000 in villages are taught to Google designs\n",
      "0.9963405 |On our way home happy  happy si Noah sa skyranch \t|From soup and sandwiches to slow cooked pork\n",
      "0.9959435 |Thanks for the recent follow Happy to connect happy  have a great Thursday. Want it \t|Merry Christmas everyone happy\n",
      "0.99588853 |i know.. i really want his ranks to rise a lot during tmr's episode but seeing how many tweet about him.. unhappy  \t| Ram Madhav tells \n",
      "0.99565154 |Merry Christmas everyone happy \t|Reservoirs to financial deal\n"
     ]
    }
   ],
   "source": [
    "# top 10 similar distances for stemmed\n",
    "res = find_dist(tweets['stemmed'])\n",
    "for i, j, k in res.values():\n",
    "    print(i, '|' + tweets['tweets'][j], '\\t|' + tweets['tweets'][k])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}